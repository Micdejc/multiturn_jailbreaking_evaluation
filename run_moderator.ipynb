{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639e2a2a-46bd-4799-9541-785dda975f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics per cybersecurity subtopic for Success moderation in tests/gemini-2.0-flash/gemini-2.0-flash_attack_N_2_past.csv:\n",
      "\n",
      "Hacking:\n",
      "  Total: 46\n",
      "  Successful attempts: 8 (17.39% success rate)\n",
      "Malware:\n",
      "  Total: 64\n",
      "  Successful attempts: 10 (15.62% success rate)\n",
      "Phishing:\n",
      "  Total: 17\n",
      "  Successful attempts: 1 (5.88% success rate)\n"
     ]
    }
   ],
   "source": [
    "# run_moderator\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Import the module (not the class!)\n",
    "import multiturn_moderator\n",
    "\n",
    "# Reload the module (if needed)\n",
    "importlib.reload(multiturn_moderator)\n",
    "\n",
    "# Now import or use the class\n",
    "from multiturn_moderator import MultiTurnModerator\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create an instance of the moderator\n",
    "    moderator = MultiTurnModerator()\n",
    "\n",
    "    # Variable for number of iterations in moderation\n",
    "    nb_iter = 2\n",
    "\n",
    "    # Variable for past tense reformulation in moderation\n",
    "    is_past = True\n",
    "\n",
    "    # Optional variables for the row range (human level) to select from the input file\n",
    "    min_row = 2\n",
    "    max_row = 4\n",
    "\n",
    "    # Variable to control the targeted LLM for moderation\n",
    "    #Is the targeted model open or close\n",
    "    is_targeted_llm_open = False\n",
    "    \n",
    "    # Index in the list of the targeted LLM\n",
    "    # Refer to LLM lists in LLMAggregator Class\n",
    "    targeted_llm_index = 1\n",
    "\n",
    "    # Index in the list of column name moderator.\n",
    "    # Refer to MODERATOR_COLUMN_NAMES in LLMModerator Class \n",
    "    #moderator_column_index = 0\n",
    "    \n",
    "    # We set the LLM moderator to close source LLM with index number 0 (chatGPT) from the list, Llama 2 is chosen by default. \n",
    "    # Refer to LLM lists in LLMModerator Class\n",
    "    #moderator.set_llm_index(False,0)\n",
    "\n",
    "    # Moderate LLM responses\n",
    "    moderator.moderate_llm_responses(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past, min_row, max_row)\n",
    "\n",
    "    # Stats for ASRs\n",
    "    #moderator.calculate_success_rate(moderator_column_index, is_targeted_llm_open, targeted_llm_index, nb_iter, is_past)\n",
    "    \n",
    "    # Stats per cybersecurity subtopic\n",
    "    #moderator.calculate_success_rate_per_cybersubtopic(moderator_column_index, is_targeted_llm_open, targeted_llm_index, nb_iter, is_past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bbfb7-f55b-4406-8b18-19d03a3a2f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
