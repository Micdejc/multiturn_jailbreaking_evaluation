{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd9ac86-43d8-4abb-b6eb-6190f3140a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success vs Human Metrics:\n",
      "\n",
      "Sub-topic: Hacking\n",
      "  MCC: 0.060\n",
      "  Cohen's Kappa: 0.050\n",
      "  Accuracy: 0.565\n",
      "  Precision: 0.200\n",
      "  Recall: 0.500\n",
      "  F1-score: 0.286\n",
      "  Pearson's Correlation (r): 0.060\n",
      "  P-value: 6.903e-01\n",
      "\n",
      "Sub-topic: Malware\n",
      "  MCC: -0.054\n",
      "  Cohen's Kappa: -0.053\n",
      "  Accuracy: 0.531\n",
      "  Precision: 0.250\n",
      "  Recall: 0.333\n",
      "  F1-score: 0.286\n",
      "  Pearson's Correlation (r): -0.054\n",
      "  P-value: 6.726e-01\n",
      "\n",
      "Sub-topic: Phishing\n",
      "  MCC: 0.245\n",
      "  Cohen's Kappa: 0.201\n",
      "  Accuracy: 0.588\n",
      "  Precision: 0.333\n",
      "  Recall: 0.750\n",
      "  F1-score: 0.462\n",
      "  Pearson's Correlation (r): 0.245\n",
      "  P-value: 3.430e-01\n",
      "\n",
      "llama-guard-3-8b Judge vs Human Metrics:\n",
      "\n",
      "Sub-topic: Hacking\n",
      "  MCC: -0.068\n",
      "  Cohen's Kappa: -0.040\n",
      "  Accuracy: 0.804\n",
      "  Precision: 0.000\n",
      "  Recall: 0.000\n",
      "  F1-score: 0.000\n",
      "  Pearson's Correlation (r): -0.068\n",
      "  P-value: 6.515e-01\n",
      "\n",
      "Sub-topic: Malware\n",
      "  MCC: 0.000\n",
      "  Cohen's Kappa: 0.000\n",
      "  Accuracy: 0.719\n",
      "  Precision: 0.000\n",
      "  Recall: 0.000\n",
      "  F1-score: 0.000\n",
      "  Pearson's Correlation (r): nan\n",
      "  P-value: nan\n",
      "\n",
      "Sub-topic: Phishing\n",
      "  MCC: 0.000\n",
      "  Cohen's Kappa: 0.000\n",
      "  Accuracy: 0.765\n",
      "  Precision: 0.000\n",
      "  Recall: 0.000\n",
      "  F1-score: 0.000\n",
      "  Pearson's Correlation (r): nan\n",
      "  P-value: nan\n",
      "\n",
      "gpt-4.1 Judge vs Human Metrics:\n",
      "\n",
      "Sub-topic: Hacking\n",
      "  MCC: 0.229\n",
      "  Cohen's Kappa: 0.174\n",
      "  Accuracy: 0.587\n",
      "  Precision: 0.261\n",
      "  Recall: 0.750\n",
      "  F1-score: 0.387\n",
      "  Pearson's Correlation (r): 0.229\n",
      "  P-value: 1.251e-01\n",
      "\n",
      "Sub-topic: Malware\n",
      "  MCC: 0.518\n",
      "  Cohen's Kappa: 0.452\n",
      "  Accuracy: 0.719\n",
      "  Precision: 0.500\n",
      "  Recall: 0.944\n",
      "  F1-score: 0.654\n",
      "  Pearson's Correlation (r): 0.518\n",
      "  P-value: 1.168e-05\n",
      "\n",
      "Sub-topic: Phishing\n",
      "  MCC: -0.033\n",
      "  Cohen's Kappa: -0.027\n",
      "  Accuracy: 0.471\n",
      "  Precision: 0.222\n",
      "  Recall: 0.500\n",
      "  F1-score: 0.308\n",
      "  Pearson's Correlation (r): -0.033\n",
      "  P-value: 9.009e-01\n",
      "\n",
      "is_jailbreak_sim_all-MiniLM-L6-v2 vs Human Metrics:\n",
      "\n",
      "Sub-topic: Hacking\n",
      "  MCC: 0.923\n",
      "  Cohen's Kappa: 0.920\n",
      "  Accuracy: 0.978\n",
      "  Precision: 1.000\n",
      "  Recall: 0.875\n",
      "  F1-score: 0.933\n",
      "  Pearson's Correlation (r): 0.923\n",
      "  P-value: 6.607e-20\n",
      "\n",
      "Sub-topic: Malware\n",
      "  MCC: 0.778\n",
      "  Cohen's Kappa: 0.776\n",
      "  Accuracy: 0.906\n",
      "  Precision: 0.800\n",
      "  Recall: 0.889\n",
      "  F1-score: 0.842\n",
      "  Pearson's Correlation (r): 0.778\n",
      "  P-value: 3.982e-14\n",
      "\n",
      "Sub-topic: Phishing\n",
      "  MCC: 0.471\n",
      "  Cohen's Kappa: 0.463\n",
      "  Accuracy: 0.824\n",
      "  Precision: 0.667\n",
      "  Recall: 0.500\n",
      "  F1-score: 0.571\n",
      "  Pearson's Correlation (r): 0.471\n",
      "  P-value: 5.649e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Desktop\\PhD_Experimentation\\Modular_Source_codes\\multiturn_evaluator.py:483: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  # Input:\n",
      "C:\\Users\\Michael\\Desktop\\PhD_Experimentation\\Modular_Source_codes\\multiturn_evaluator.py:483: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  # Input:\n"
     ]
    }
   ],
   "source": [
    "# run_evaluator\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Import the module (not the class!)\n",
    "import multiturn_evaluator\n",
    "\n",
    "# Reload the module (if needed)\n",
    "importlib.reload(multiturn_evaluator)\n",
    "\n",
    "# Now import or use the class\n",
    "from multiturn_evaluator import MultiTurnEvaluator\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create an instance of the moderator\n",
    "    evaluator = MultiTurnEvaluator()\n",
    "\n",
    "    # Variable for number of iterations in moderation\n",
    "    nb_iter = 1\n",
    "\n",
    "    # Variable for past tense reformulation in moderation\n",
    "    is_past = True\n",
    "\n",
    "    # Variable to specify if training or not\n",
    "    is_training = False\n",
    "\n",
    "    # Optional variables for the row range (human level) to select from the input file\n",
    "    min_row = None\n",
    "    max_row = None\n",
    "\n",
    "    # Variable to control the targeted LLM for moderation\n",
    "    #Is the targeted model open or close\n",
    "    is_targeted_llm_open = False\n",
    "    \n",
    "    # Index in the list of the targeted LLM\n",
    "    # Refer to LLM lists in LLMAggregator Class\n",
    "    targeted_llm_index = 1\n",
    "\n",
    "    # Extract human refusal set from LLM responses\n",
    "    #evaluator.human_moderation_extraction_embedding(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past, min_row, max_row)\n",
    "\n",
    "    # Calculate semantic distances for LLM responses set\n",
    "    evaluator.llm_reponse_semantic_similarities(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past, is_training, min_row, max_row)\n",
    "\n",
    "    # Assess jailbreaking using semantic similarities for LLM responses set\n",
    "    #evaluator.llm_reponse_semantic_evaluation(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past, min_row, max_row)\n",
    "\n",
    "    # Calculate evaluation mertics for LLM responses set for stats\n",
    "    #evaluator.calculate_evaluation_metrics(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past)\n",
    "\n",
    "    # Calculate evaluation mertics per cyber subtopic for LLM responses set for stats\n",
    "    #evaluator.calculate_evaluation_metrics_per_cybersubtopic(is_targeted_llm_open, targeted_llm_index, nb_iter, is_past)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ee3ae-b0eb-4597-9471-69add8229e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
